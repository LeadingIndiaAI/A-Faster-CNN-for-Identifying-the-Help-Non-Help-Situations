{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_data import load_data\n",
    "from utils.load_model import load_model\n",
    "from utils.test_model import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, dataset_size, class_name = load_data('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_idx = [2, 8, 11, 14, 17, 21, 24, 27, 30, 33, 37, 40, 43, 46, 49, 53, 56, 59, 62, 65]\n",
    "skip_layers = [2, 11, 14, 17, 24, 33, 40, 49, 56, 59, 65]\n",
    "prune_layers = [x for x in conv_idx if x not in skip_layers]\n",
    "prune_prob = [0.1, 0.2, 0.3, 0.4, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, mod):\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        self.name = type(mod)\n",
    "        \n",
    "        self.prev_pruned = None\n",
    "        self.pruned = None\n",
    "        self.no_filter = None\n",
    "        self.mask_filter = None\n",
    "        \n",
    "        self.layer_id = 1\n",
    "            \n",
    "    def make_mask(self, mod, skip_layers, prune_layers):\n",
    "        \n",
    "        no_filter = mod.weight.data.shape[0]\n",
    "\n",
    "        if mod.kernel_size == (1,1):\n",
    "            self.pruned = False\n",
    "            self.no_filter = None\n",
    "            self.mask_filter = None\n",
    "            return\n",
    "        \n",
    "        elif self.layer_id in skip_layers:\n",
    "            mask_filter = torch.ones(no_filter)\n",
    "            \n",
    "            self.pruned = False\n",
    "            self.no_filter = no_filter\n",
    "            self.mask_filter = mask_filter\n",
    "            return\n",
    "        \n",
    "        elif self.layer_id in prune_layers:\n",
    "            if self.layer_id <= 8:\n",
    "                stage = 0\n",
    "            elif self.layer_id <= 21:\n",
    "                stage = 1\n",
    "            elif self.layer_id <= 36:\n",
    "                stage = 2\n",
    "            elif self.layer_id <= 53:\n",
    "                stage = 3\n",
    "            else:\n",
    "                stage = 4\n",
    "            prune_prob_stage = prune_prob[stage]\n",
    "            weight_copy = mod.weight.data.abs().clone().cpu().numpy()\n",
    "            L1_norm = np.sum(weight_copy, axis = (1,2,3))\n",
    "            num_keep = int(no_filter * (1 - prune_prob_stage))\n",
    "            arg_max = np.argsort(L1_norm)\n",
    "            arg_max_rev = arg_max[::-1][:num_keep]\n",
    "            mask_filter = torch.zeros(no_filter)\n",
    "            mask_filter[arg_max_rev.tolist()] = 1\n",
    "            \n",
    "            self.pruned = True\n",
    "            self.no_filter = num_keep\n",
    "            self.mask_filter = mask_filter\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruneDDL():\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        \n",
    "    def append(self, mod, process = False):\n",
    "        \n",
    "        if self.head == None:\n",
    "            self.head = Node(mod)\n",
    "            self.head.next = None\n",
    "            self.head.prev = None\n",
    "        else:\n",
    "            ptr = self.head\n",
    "            while ptr.next!=None:\n",
    "                ptr = ptr.next\n",
    "            new_node = Node(mod)\n",
    "            new_node.next = None\n",
    "            ptr.next = new_node\n",
    "            new_node.prev = ptr\n",
    "        \n",
    "            if new_node.prev == None:\n",
    "                new_node.layer_id = 2\n",
    "            else:\n",
    "                new_node.layer_id = new_node.prev.layer_id + 1\n",
    "            \n",
    "            ptr = self.head\n",
    "            \n",
    "            if isinstance(mod, nn.Conv2d) and process:\n",
    "                \n",
    "                if new_node.layer_id!=2:\n",
    "                    prev_layer_id = conv_idx[conv_idx.index(new_node.layer_id) - 1]\n",
    "                    while ptr.layer_id!=prev_layer_id:\n",
    "                        ptr = ptr.next\n",
    "\n",
    "                    if ptr.pruned:\n",
    "                        new_node.prev_pruned = True\n",
    "                \n",
    "                new_node.make_mask(mod, skip_layers, prune_layers)\n",
    "                \n",
    "    def prev_conv_dim(self, layer_id):\n",
    "        \n",
    "        if layer_id == 2:\n",
    "            return\n",
    "        prev_layer_id = conv_idx[conv_idx.index(layer_id) - 1]\n",
    "        ptr = self.head\n",
    "        \n",
    "        while ptr.layer_id!=prev_layer_id:\n",
    "            ptr = ptr.next\n",
    "        \n",
    "        return ptr.no_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model_orig = load_model('../models/resnet18_01')\n",
    "model_orig_ddl = PruneDDL()\n",
    "\n",
    "for m in model_orig.modules():\n",
    "    model_orig_ddl.append(m, True)\n",
    "\n",
    "m = [x for x in model_orig.modules() if isinstance(x, nn.Linear)]\n",
    "model_orig_ddl.append(m[0])\n",
    "\n",
    "node_orig = model_orig_ddl.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prune = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m0, m1 in zip(model_orig.modules(), model_prune.modules()):\n",
    "    \n",
    "    if node_orig == None:\n",
    "        break\n",
    "        \n",
    "    if isinstance(m0, nn.Conv2d):\n",
    "        \n",
    "        if m0.kernel_size == (1,1):\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            \n",
    "        if node_orig.layer_id == 2:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            \n",
    "        if node_orig.pruned:\n",
    "            mask = node_orig.mask_filter\n",
    "            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "            if idx.size == 1:\n",
    "                idx = np.resize(idx, (1,))\n",
    "            w = m0.weight.data[idx.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w.clone()\n",
    "            \n",
    "        if node_orig.prev_pruned:\n",
    "            ptr = model_orig_ddl.head\n",
    "            prev_layer_id = conv_idx[conv_idx.index(node_orig.layer_id)-1]\n",
    "            while ptr.layer_id!=prev_layer_id:\n",
    "                ptr = ptr.next\n",
    "            mask = ptr.mask_filter\n",
    "            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "            if idx.size == 1:\n",
    "                idx = np.resize(idx, (1,))\n",
    "            w = m0.weight.data[:, idx.tolist(), :, :].clone()\n",
    "            m1.weight.data = w.clone()\n",
    "            \n",
    "    elif isinstance(m0, nn.BatchNorm2d):\n",
    "        assert isinstance(m1, nn.BatchNorm2d)\n",
    "        \n",
    "        if node_orig.prev.pruned:\n",
    "            mask = node_orig.prev.mask_filter\n",
    "            idx = np.squeeze(np.argwhere(np.asarray(mask.cpu().numpy())))\n",
    "            if idx.size == 1:\n",
    "                idx = np.resize(idx, (1,))\n",
    "            m1.weight.data = m0.weight.data[idx.tolist()].clone()\n",
    "            m1.bias.data = m0.bias.data[idx.tolist()].clone()\n",
    "            m1.running_mean = m0.running_mean[idx.tolist()].clone()\n",
    "            m1.running_var = m0.running_var[idx.tolist()].clone()\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "            \n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    "        m1.bias.data = m0.bias.data.clone()\n",
    "            \n",
    "    node_orig = node_orig.next  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 540 test images is 93.33\n"
     ]
    }
   ],
   "source": [
    "test_model(model_orig, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 540 test images is 85.56\n"
     ]
    }
   ],
   "source": [
    "test_model(model_prune, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_prune.state_dict(), '../models/pruned_model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize import visualize_model\n",
    "from utils.train_model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_prune.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "trainloaders = {x: dataloaders[x] for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.3407 Acc: 0.8685\n",
      "val Loss: 0.1921 Acc: 0.9247\n",
      "Epoch time: 2m 41s\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.2614 Acc: 0.9061\n",
      "val Loss: 0.1673 Acc: 0.9486\n",
      "Epoch time: 2m 43s\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2304 Acc: 0.9100\n",
      "val Loss: 0.1776 Acc: 0.9452\n",
      "Epoch time: 2m 42s\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.9161\n",
      "val Loss: 0.3381 Acc: 0.9144\n",
      "Epoch time: 2m 41s\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1890 Acc: 0.9284\n",
      "val Loss: 0.1838 Acc: 0.9384\n",
      "Epoch time: 2m 59s\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1764 Acc: 0.9320\n",
      "val Loss: 0.2031 Acc: 0.9281\n",
      "Epoch time: 2m 57s\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1767 Acc: 0.9323\n",
      "val Loss: 0.1432 Acc: 0.9384\n",
      "Epoch time: 2m 46s\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.1102 Acc: 0.9615\n",
      "val Loss: 0.1516 Acc: 0.9555\n",
      "Epoch time: 3m 10s\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1047 Acc: 0.9612\n",
      "val Loss: 0.1282 Acc: 0.9555\n",
      "Epoch time: 2m 57s\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1016 Acc: 0.9630\n",
      "val Loss: 0.1218 Acc: 0.9555\n",
      "Epoch time: 2m 52s\n",
      "\n",
      "Training complete in 28m 27s\n",
      "Best val Acc: 0.955479\n"
     ]
    }
   ],
   "source": [
    "model_prune_retrain = train_model(model_prune, trainloaders, dataset_size, criterion, optimizer, exp_lr_scheduler, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on 540 test images is 95.56\n"
     ]
    }
   ],
   "source": [
    "test_model(model_prune_retrain, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prune_retrain.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.rand(1, 3, 224, 224)\n",
    "example = example.to(device)\n",
    "traced_script_module = torch.jit.trace(model_prune_retrain, example)\n",
    "traced_script_module.save('../models/model_pruned.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(model_orig, example)\n",
    "traced_script_module.save('../models/model_orig.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model': model_orig.__class__,\n",
    "    'state_dict' : model_orig.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, '../models/model_orig_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model_o = checkpoint['model']\n",
    "    model_o.load_state_dict(torch.load('../models/resnet18_01'))\n",
    "    \n",
    "    return model_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_state_dict() missing 1 required positional argument: 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-1a91221320ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../models/model_orig_checkpoint.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-f39d3c1393c2>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../models/resnet18_01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: load_state_dict() missing 1 required positional argument: 'state_dict'"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('../models/model_orig_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_prune_retrain.state_dict(), '../models/pruned_model_retrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
